#!/bin/bash

# =============================================================================
# AI Forge - Production-Grade DevOps Script
# =============================================================================
#
# Usage:
#   ./forge start       - Start all services
#   ./forge stop        - Stop all services
#   ./forge restart     - Restart all services
#   ./forge status      - Check status of all services
#   ./forge logs [svc]  - View logs (frontend|backend|ollama|all)
#   ./forge health      - Run health checks
#   ./forge clean       - Clean up and reset
#   ./forge setup       - First-time setup
#   ./forge help        - Show this help
#
# =============================================================================

set -e

# =============================================================================
# Configuration
# =============================================================================

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_NAME="ai-forge"

# Directories
FRONTEND_DIR="$SCRIPT_DIR/frontend"
BACKEND_DIR="$SCRIPT_DIR"
LOG_DIR="$SCRIPT_DIR/.logs"
PID_DIR="$SCRIPT_DIR/.pids"

# Ports
FRONTEND_PORT=3000
BACKEND_PORT=8000
OLLAMA_PORT=11434

# Colors
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color
BOLD='\033[1m'

# =============================================================================
# Utility Functions
# =============================================================================

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[âœ“]${NC} $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $1"
}

log_error() {
    echo -e "${RED}[âœ—]${NC} $1"
}

log_header() {
    echo -e "\n${BOLD}${CYAN}â”â”â” $1 â”â”â”${NC}\n"
}

ensure_dirs() {
    mkdir -p "$LOG_DIR" "$PID_DIR"
}

check_command() {
    if ! command -v "$1" &> /dev/null; then
        log_error "$1 is not installed. Please install it first."
        return 1
    fi
}

check_port() {
    local port=$1
    if lsof -Pi :$port -sTCP:LISTEN -t >/dev/null 2>&1; then
        return 0  # Port is in use
    else
        return 1  # Port is free
    fi
}

wait_for_port() {
    local port=$1
    local service=$2
    local timeout=${3:-30}
    local count=0
    
    while ! check_port $port; do
        sleep 1
        count=$((count + 1))
        if [ $count -ge $timeout ]; then
            log_error "$service did not start within ${timeout}s"
            return 1
        fi
    done
    return 0
}

get_pid() {
    local service=$1
    local pid_file="$PID_DIR/${service}.pid"
    if [ -f "$pid_file" ]; then
        cat "$pid_file"
    fi
}

save_pid() {
    local service=$1
    local pid=$2
    echo "$pid" > "$PID_DIR/${service}.pid"
}

remove_pid() {
    local service=$1
    rm -f "$PID_DIR/${service}.pid"
}

is_running() {
    local service=$1
    local pid=$(get_pid "$service")
    if [ -n "$pid" ] && kill -0 "$pid" 2>/dev/null; then
        return 0
    fi
    return 1
}

# =============================================================================
# Service Functions
# =============================================================================

# -----------------------------------------------------------------------------
# Ollama
# -----------------------------------------------------------------------------

start_ollama() {
    log_info "Starting Ollama..."
    
    if check_port $OLLAMA_PORT; then
        log_success "Ollama already running on port $OLLAMA_PORT"
        return 0
    fi
    
    # Start Ollama in background
    ollama serve > "$LOG_DIR/ollama.log" 2>&1 &
    local pid=$!
    save_pid "ollama" $pid
    
    if wait_for_port $OLLAMA_PORT "Ollama" 10; then
        log_success "Ollama started (PID: $pid)"
    else
        log_warn "Ollama may not have started correctly"
    fi
}

stop_ollama() {
    log_info "Stopping Ollama..."
    
    # Try graceful shutdown first
    pkill -f "ollama serve" 2>/dev/null || true
    remove_pid "ollama"
    
    sleep 1
    
    if ! check_port $OLLAMA_PORT; then
        log_success "Ollama stopped"
    else
        log_warn "Ollama may still be running"
    fi
}

# -----------------------------------------------------------------------------
# Backend (FastAPI)
# -----------------------------------------------------------------------------

start_backend() {
    log_info "Starting Backend..."
    
    if check_port $BACKEND_PORT; then
        log_success "Backend already running on port $BACKEND_PORT"
        return 0
    fi
    
    cd "$BACKEND_DIR"
    
    # Check for virtual environment and activate
    if [ -d ".venv" ]; then
        source .venv/bin/activate
    elif [ -d "venv" ]; then
        source venv/bin/activate
    fi
    
    # Start with uvicorn - using conductor.service:app
    python -m uvicorn conductor.service:app \
        --host 0.0.0.0 \
        --port $BACKEND_PORT \
        --reload \
        > "$LOG_DIR/backend.log" 2>&1 &
    
    local pid=$!
    save_pid "backend" $pid
    
    if wait_for_port $BACKEND_PORT "Backend" 15; then
        log_success "Backend started (PID: $pid) â†’ http://localhost:$BACKEND_PORT"
    else
        log_error "Backend failed to start. Check logs: $LOG_DIR/backend.log"
        cat "$LOG_DIR/backend.log" | tail -20
        return 1
    fi
}

stop_backend() {
    log_info "Stopping Backend..."
    
    local pid=$(get_pid "backend")
    if [ -n "$pid" ]; then
        kill $pid 2>/dev/null || true
        remove_pid "backend"
    fi
    
    # Also kill any stray uvicorn processes
    pkill -f "uvicorn ai_forge" 2>/dev/null || true
    
    sleep 1
    
    if ! check_port $BACKEND_PORT; then
        log_success "Backend stopped"
    else
        log_warn "Backend may still be running"
    fi
}

# -----------------------------------------------------------------------------
# Frontend (Vite)
# -----------------------------------------------------------------------------

start_frontend() {
    log_info "Starting Frontend..."
    
    if check_port $FRONTEND_PORT; then
        log_success "Frontend already running on port $FRONTEND_PORT"
        return 0
    fi
    
    cd "$FRONTEND_DIR"
    
    # Install dependencies if needed
    if [ ! -d "node_modules" ]; then
        log_info "Installing frontend dependencies..."
        npm install
    fi
    
    # Start Vite dev server
    npm run dev > "$LOG_DIR/frontend.log" 2>&1 &
    local pid=$!
    save_pid "frontend" $pid
    
    if wait_for_port $FRONTEND_PORT "Frontend" 20; then
        log_success "Frontend started (PID: $pid) â†’ http://localhost:$FRONTEND_PORT"
    else
        log_error "Frontend failed to start. Check logs: $LOG_DIR/frontend.log"
        return 1
    fi
}

stop_frontend() {
    log_info "Stopping Frontend..."
    
    local pid=$(get_pid "frontend")
    if [ -n "$pid" ]; then
        kill $pid 2>/dev/null || true
        remove_pid "frontend"
    fi
    
    # Also kill any stray vite processes
    pkill -f "vite" 2>/dev/null || true
    
    sleep 1
    
    if ! check_port $FRONTEND_PORT; then
        log_success "Frontend stopped"
    else
        log_warn "Frontend may still be running"
    fi
}

# =============================================================================
# Commands
# =============================================================================

cmd_start() {
    local service=${1:-all}
    
    log_header "Starting AI Forge"
    ensure_dirs
    
    case $service in
        all)
            start_ollama
            start_backend
            start_frontend
            echo ""
            cmd_status
            ;;
        ollama)
            start_ollama
            ;;
        backend)
            start_backend
            ;;
        frontend)
            start_frontend
            ;;
        *)
            log_error "Unknown service: $service"
            echo "Available services: ollama, backend, frontend, all"
            exit 1
            ;;
    esac
}

cmd_stop() {
    local service=${1:-all}
    
    log_header "Stopping AI Forge"
    
    case $service in
        all)
            stop_frontend
            stop_backend
            stop_ollama
            ;;
        ollama)
            stop_ollama
            ;;
        backend)
            stop_backend
            ;;
        frontend)
            stop_frontend
            ;;
        *)
            log_error "Unknown service: $service"
            exit 1
            ;;
    esac
    
    log_success "All services stopped"
}

cmd_restart() {
    local service=${1:-all}
    
    log_header "Restarting AI Forge"
    
    cmd_stop "$service"
    sleep 2
    cmd_start "$service"
}

cmd_status() {
    log_header "Service Status"
    
    printf "%-12s %-10s %-8s %-30s\n" "SERVICE" "STATUS" "PORT" "URL"
    printf "%-12s %-10s %-8s %-30s\n" "-------" "------" "----" "---"
    
    # Ollama
    if check_port $OLLAMA_PORT; then
        printf "%-12s ${GREEN}%-10s${NC} %-8s %-30s\n" "Ollama" "Running" "$OLLAMA_PORT" "http://localhost:$OLLAMA_PORT"
    else
        printf "%-12s ${RED}%-10s${NC} %-8s %-30s\n" "Ollama" "Stopped" "$OLLAMA_PORT" "-"
    fi
    
    # Backend
    if check_port $BACKEND_PORT; then
        printf "%-12s ${GREEN}%-10s${NC} %-8s %-30s\n" "Backend" "Running" "$BACKEND_PORT" "http://localhost:$BACKEND_PORT"
    else
        printf "%-12s ${RED}%-10s${NC} %-8s %-30s\n" "Backend" "Stopped" "$BACKEND_PORT" "-"
    fi
    
    # Frontend
    if check_port $FRONTEND_PORT; then
        printf "%-12s ${GREEN}%-10s${NC} %-8s %-30s\n" "Frontend" "Running" "$FRONTEND_PORT" "http://localhost:$FRONTEND_PORT"
    else
        printf "%-12s ${RED}%-10s${NC} %-8s %-30s\n" "Frontend" "Stopped" "$FRONTEND_PORT" "-"
    fi
    
    echo ""
}

cmd_logs() {
    local service=${1:-all}
    
    case $service in
        all)
            log_header "All Logs (Ctrl+C to exit)"
            tail -f "$LOG_DIR"/*.log 2>/dev/null || log_warn "No logs found"
            ;;
        frontend)
            tail -f "$LOG_DIR/frontend.log" 2>/dev/null || log_warn "No frontend logs"
            ;;
        backend)
            tail -f "$LOG_DIR/backend.log" 2>/dev/null || log_warn "No backend logs"
            ;;
        ollama)
            tail -f "$LOG_DIR/ollama.log" 2>/dev/null || log_warn "No ollama logs"
            ;;
        *)
            log_error "Unknown service: $service"
            echo "Available: frontend, backend, ollama, all"
            exit 1
            ;;
    esac
}

cmd_health() {
    log_header "Health Checks"
    
    local all_healthy=true
    
    # Check Ollama
    printf "Checking Ollama... "
    if curl -s "http://localhost:$OLLAMA_PORT/api/tags" > /dev/null 2>&1; then
        echo -e "${GREEN}âœ“ Healthy${NC}"
    else
        echo -e "${RED}âœ— Unhealthy${NC}"
        all_healthy=false
    fi
    
    # Check Backend
    printf "Checking Backend... "
    if curl -s "http://localhost:$BACKEND_PORT/health" > /dev/null 2>&1; then
        echo -e "${GREEN}âœ“ Healthy${NC}"
    else
        echo -e "${RED}âœ— Unhealthy${NC}"
        all_healthy=false
    fi
    
    # Check Frontend
    printf "Checking Frontend... "
    if curl -s "http://localhost:$FRONTEND_PORT/" > /dev/null 2>&1; then
        echo -e "${GREEN}âœ“ Healthy${NC}"
    else
        echo -e "${RED}âœ— Unhealthy${NC}"
        all_healthy=false
    fi
    
    echo ""
    
    if $all_healthy; then
        log_success "All services healthy!"
        return 0
    else
        log_error "Some services are unhealthy"
        return 1
    fi
}

cmd_clean() {
    log_header "Cleaning Up"
    
    cmd_stop all
    
    log_info "Removing logs..."
    rm -rf "$LOG_DIR"
    
    log_info "Removing PID files..."
    rm -rf "$PID_DIR"
    
    log_info "Removing frontend build..."
    rm -rf "$FRONTEND_DIR/dist"
    rm -rf "$FRONTEND_DIR/node_modules/.vite"
    
    log_info "Removing Python cache..."
    find "$BACKEND_DIR" -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
    find "$BACKEND_DIR" -type f -name "*.pyc" -delete 2>/dev/null || true
    
    log_success "Cleanup complete"
}

cmd_setup() {
    log_header "First-Time Setup"
    
    # Check prerequisites
    log_info "Checking prerequisites..."
    
    check_command "node" || exit 1
    check_command "npm" || exit 1
    check_command "python3" || exit 1
    check_command "ollama" || exit 1
    
    log_success "All prerequisites installed"
    
    # Setup frontend
    log_info "Setting up frontend..."
    cd "$FRONTEND_DIR"
    
    if [ ! -f ".env" ] && [ -f ".env.example" ]; then
        cp .env.example .env
        log_info "Created .env from .env.example"
    fi
    
    npm install
    log_success "Frontend dependencies installed"
    
    # Setup backend
    log_info "Setting up backend..."
    cd "$BACKEND_DIR"
    
    if [ ! -d "venv" ] && [ ! -d ".venv" ]; then
        python3 -m venv venv
        source venv/bin/activate
        pip install -e ".[dev]"
        log_success "Backend virtual environment created"
    else
        log_info "Virtual environment already exists"
    fi
    
    # Pull default model
    log_info "Pulling default Ollama model (llama3.2:3b)..."
    ollama pull llama3.2:3b || log_warn "Could not pull model. You may need to do this manually."
    
    log_success "Setup complete! Run './forge start' to begin."
}

cmd_help() {
    cat << 'EOF'

ðŸ”¥ AI Forge - DevOps Control Script

USAGE:
    ./forge <command> [service]

COMMANDS:
    start [service]     Start services (default: all)
    stop [service]      Stop services (default: all)
    restart [service]   Restart services (default: all)
    status              Show status of all services
    logs [service]      Tail logs (default: all)
    health              Run health checks on all services
    clean               Stop all and clean up temp files
    setup               First-time setup (install deps, create env)
    help                Show this help message

SERVICES:
    all                 All services (default)
    frontend            Vite dev server (port 5173)
    backend             FastAPI server (port 8000)
    ollama              Ollama model server (port 11434)

EXAMPLES:
    ./forge start                 # Start everything
    ./forge stop                  # Stop everything
    ./forge restart backend       # Restart only backend
    ./forge logs frontend         # Tail frontend logs
    ./forge status                # Check what's running

QUICK START:
    ./forge setup                 # First time only
    ./forge start                 # Start all services
    open http://localhost:5173    # Open in browser

EOF
}

# =============================================================================
# Main Entry Point
# =============================================================================

main() {
    local command=${1:-help}
    shift || true
    
    case $command in
        start)
            cmd_start "$@"
            ;;
        stop)
            cmd_stop "$@"
            ;;
        restart)
            cmd_restart "$@"
            ;;
        status)
            cmd_status
            ;;
        logs)
            cmd_logs "$@"
            ;;
        health)
            cmd_health
            ;;
        clean)
            cmd_clean
            ;;
        setup)
            cmd_setup
            ;;
        help|--help|-h)
            cmd_help
            ;;
        *)
            log_error "Unknown command: $command"
            cmd_help
            exit 1
            ;;
    esac
}

# Run main with all arguments
main "$@"
