# AI Forge - Global Configuration
# Default settings for the Local LLM Fine-Tuning Service

# Hardware Detection
hardware:
  platform: "apple_silicon"  # apple_silicon | nvidia | cpu
  min_memory_gb: 8
  recommended_memory_gb: 16
  max_model_size: "13B"  # Conservative for 16GB
  
# Training Defaults
training:
  default_epochs: 3
  default_batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 2e-4
  warmup_ratio: 0.03
  max_seq_length: 2048
  fp16: true
  seed: 42
  
# Model Defaults
model:
  default_base: "unsloth/Llama-3.2-3B-Instruct"
  load_in_4bit: true  # QLoRA
  dtype: "float16"
  
# Paths
paths:
  data_dir: "./data"
  output_dir: "./output"
  models_dir: "./models"
  logs_dir: "./logs"
  cache_dir: "./cache"
  
# Logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  metrics_log_interval: 10  # steps
  
# API Service
api:
  host: "0.0.0.0"
  port: 8000
  workers: 1
  timeout: 3600  # 1 hour for long training jobs
  
# Ollama Integration
ollama:
  host: "http://localhost:11434"
  default_temperature: 0.7
  default_top_k: 40
  health_check_interval: 30  # seconds
