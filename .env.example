# =============================================================================
# AI Forge Environment Configuration
# =============================================================================
# Copy this file to .env and customize for your environment

# =============================================================================
# General Settings
# =============================================================================
AI_FORGE_ENV=development
AI_FORGE_DEBUG=true
AI_FORGE_LOG_LEVEL=INFO

# =============================================================================
# Paths
# =============================================================================
AI_FORGE_DATA_DIR=./data
AI_FORGE_OUTPUT_DIR=./output
AI_FORGE_MODELS_DIR=./models
AI_FORGE_LOGS_DIR=./logs
AI_FORGE_CACHE_DIR=./cache

# =============================================================================
# API Service Configuration
# =============================================================================
AI_FORGE_API_HOST=0.0.0.0
AI_FORGE_API_PORT=8000
AI_FORGE_API_WORKERS=1
AI_FORGE_API_TIMEOUT=3600

# =============================================================================
# Ollama Configuration
# =============================================================================
OLLAMA_HOST=http://localhost:11434
OLLAMA_DEFAULT_MODEL=llama3:latest
OLLAMA_HEALTH_CHECK_INTERVAL=30

# =============================================================================
# Training Defaults
# =============================================================================
# Base model for fine-tuning
DEFAULT_BASE_MODEL=unsloth/Llama-3.2-3B-Instruct

# Training parameters
DEFAULT_EPOCHS=3
DEFAULT_BATCH_SIZE=4
DEFAULT_LEARNING_RATE=2e-4
DEFAULT_MAX_SEQ_LENGTH=2048

# PiSSA/LoRA settings
USE_PISSA=true
PISSA_RANK=64
PISSA_ALPHA=128
PISSA_DROPOUT=0.05

# Quantization
LOAD_IN_4BIT=true
QUANTIZATION_TYPE=nf4

# =============================================================================
# Hardware Settings
# =============================================================================
# Automatically detected, but can be overridden
# DEVICE=mps  # mps (Mac), cuda, cpu
# MAX_MEMORY_GB=16

# =============================================================================
# HuggingFace Configuration
# =============================================================================
# Uncomment and set if you need private model access
# HF_TOKEN=your_huggingface_token_here
# HF_HOME=~/.cache/huggingface

# =============================================================================
# Weights & Biases (Optional)
# =============================================================================
# WANDB_API_KEY=your_wandb_key_here
# WANDB_PROJECT=ai-forge
# WANDB_DISABLED=true

# =============================================================================
# Security (Production)
# =============================================================================
# API_KEY=your_api_key_here
# ALLOWED_HOSTS=localhost,127.0.0.1
# CORS_ORIGINS=http://localhost:3000
